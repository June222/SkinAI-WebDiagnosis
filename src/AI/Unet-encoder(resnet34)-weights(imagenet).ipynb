{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install albumentations\n",
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgjJpdqtAECa",
        "outputId": "253e201a-d0e2-4851-89eb-036932a2d276"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m92.2/106.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.18.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.23.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=c1200b95d02a3b878ee54fb6ea721879dcbe254ab2d91f4b92d5f5f68daa716c\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=8ad0e8b99658365278952ce28f1d8bf4a49abb7e0536d56c219f4a5dfbea8461\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.9.0.80)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.12.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hnZiHyh7_tfH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from albumentations import Compose, Normalize, Resize, CenterCrop\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from segmentation_models_pytorch import Unet\n",
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브를 마운트합니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wevv_crIAGvF",
        "outputId": "07bb55b9-746d-4f98-80b2-a8e0f6fd60d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/TrainData.csv')\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/ValidData.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/TestData.csv')\n",
        "\n",
        "# Utility functions\n",
        "def rle_decode(mask_rle, shape=(256, 256)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return\n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    s = list(map(int, mask_rle.split()))\n",
        "    starts, lengths = s[0::2], s[1::2]\n",
        "    starts = np.asarray(starts) - 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T\n",
        "\n",
        "class LesionDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transforms=None):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.df.iloc[idx]['Image']\n",
        "        img_path = os.path.join(self.image_dir, img_name + '.jpg')\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            raise FileNotFoundError(f\"Image file {img_path} not found\")\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Failed to load image file {img_path}\")\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask_rle = self.df.iloc[idx]['EncodedPixels']\n",
        "        mask = rle_decode(mask_rle, shape=image.shape[:2])\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        mask = np.expand_dims(mask, axis=0)  # Add channel dimension to the mask\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "IDHokxmg_9Zo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "transforms = Compose([\n",
        "    CenterCrop(300, 300),\n",
        "    Resize(224, 224),\n",
        "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "], additional_targets={'mask': 'mask'}, is_check_shapes=False)\n",
        "\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = LesionDataset(train_df, '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/images/', transforms=transforms)\n",
        "valid_dataset = LesionDataset(valid_df, '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/images/', transforms=transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "uEZXPFkoAt8M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model setup\n",
        "ENCODER = 'resnet34'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = ['lesion']\n",
        "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
        "\n",
        "model = Unet(encoder_name=ENCODER,\n",
        "             encoder_weights=ENCODER_WEIGHTS,\n",
        "             classes=len(CLASSES),\n",
        "             activation=ACTIVATION)\n",
        "\n",
        "preprocess_input = get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "\n",
        "# Training setup\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "gc1MdppJBRax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac0e3f0-675a-4162-941d-b707259f9990"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 172MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor, threshold: float = 0.5):\n",
        "    outputs = outputs > threshold\n",
        "    labels = labels > threshold  # Convert labels to boolean as well\n",
        "    intersection = (outputs & labels).float().sum((1, 2, 3))\n",
        "    union = (outputs | labels).float().sum((1, 2, 3))\n",
        "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "    return iou.mean().item()\n",
        "\n",
        "def dice_coef(outputs: torch.Tensor, labels: torch.Tensor, threshold: float = 0.5):\n",
        "    outputs = outputs > threshold\n",
        "    labels = labels > threshold  # Convert labels to boolean as well\n",
        "    intersection = (outputs & labels).float().sum((1, 2, 3))\n",
        "    dice = (2. * intersection + 1e-6) / (outputs.float().sum((1, 2, 3)) + labels.float().sum((1, 2, 3)) + 1e-6)\n",
        "    return dice.mean().item()"
      ],
      "metadata": {
        "id": "GbcOHvAhBt3m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    train_iou = 0\n",
        "    train_dice = 0\n",
        "\n",
        "    for images, masks in train_loader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.float().to(device)  # Convert masks to float\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        outputs = torch.sigmoid(outputs)  # Apply sigmoid activation for thresholding\n",
        "        train_iou += iou_pytorch(outputs, masks)\n",
        "        train_dice += dice_coef(outputs, masks)\n",
        "\n",
        "    train_iou /= len(train_loader)\n",
        "    train_dice /= len(train_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader)}, IoU: {train_iou}, Dice: {train_dice}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_iou = 0\n",
        "    val_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in valid_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.float().to(device)  # Convert masks to float\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            outputs = torch.sigmoid(outputs)  # Apply sigmoid activation for thresholding\n",
        "            val_iou += iou_pytorch(outputs, masks)\n",
        "            val_dice += dice_coef(outputs, masks)\n",
        "\n",
        "    val_iou /= len(valid_loader)\n",
        "    val_dice /= len(valid_loader)\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss/len(valid_loader)}, IoU: {val_iou}, Dice: {val_dice}\")\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/best_model.pth')\n",
        "        print(f\"Model saved at epoch {epoch+1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BenFcmuBT1s",
        "outputId": "cacc54aa-86ec-4dc5-d078-9b76ae90d264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5371626620878003, IoU: 0.5896220497801871, Dice: 0.6965784303501933\n",
            "Validation Loss: 0.5078391194343567, IoU: 0.5842976943254471, Dice: 0.6917821450233459\n",
            "Model saved at epoch 1\n",
            "Epoch 2/10, Loss: 0.5053838477163257, IoU: 0.5898029260828109, Dice: 0.6966990130747149\n",
            "Validation Loss: 0.5044890949726105, IoU: 0.5842976943254471, Dice: 0.6917821450233459\n",
            "Model saved at epoch 2\n",
            "Epoch 3/10, Loss: 0.49886200786707646, IoU: 0.590485998048278, Dice: 0.6972839575327799\n",
            "Validation Loss: 0.5021552278995514, IoU: 0.5842976943254471, Dice: 0.6917821450233459\n",
            "Model saved at epoch 3\n",
            "Epoch 4/10, Loss: 0.4955671351707862, IoU: 0.5922187478272263, Dice: 0.6986568016027976\n",
            "Validation Loss: 0.4993251483440399, IoU: 0.5842977339029312, Dice: 0.6917822065353394\n",
            "Model saved at epoch 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 가중치 로드\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/best_model.pth'))"
      ],
      "metadata": {
        "id": "WRUhTSz1FH1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbc6026-b94d-4397-8897-249d48e65d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    train_iou = 0\n",
        "    train_dice = 0\n",
        "\n",
        "    for images, masks in train_loader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.float().to(device)  # Convert masks to float\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        outputs = torch.sigmoid(outputs)  # Apply sigmoid activation for thresholding\n",
        "        train_iou += iou_pytorch(outputs, masks)\n",
        "        train_dice += dice_coef(outputs, masks)\n",
        "\n",
        "    train_iou /= len(train_loader)\n",
        "    train_dice /= len(train_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader)}, IoU: {train_iou}, Dice: {train_dice}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_iou = 0\n",
        "    val_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in valid_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.float().to(device)  # Convert masks to float\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            outputs = torch.sigmoid(outputs)  # Apply sigmoid activation for thresholding\n",
        "            val_iou += iou_pytorch(outputs, masks)\n",
        "            val_dice += dice_coef(outputs, masks)\n",
        "\n",
        "    val_iou /= len(valid_loader)\n",
        "    val_dice /= len(valid_loader)\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss/len(valid_loader)}, IoU: {val_iou}, Dice: {val_dice}\")\n",
        "\n",
        "    # Save the model if validation loss has decreased\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/best_model.pth')\n",
        "        print(f\"Model saved at epoch {epoch+1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGOzTdKc3VU1",
        "outputId": "06526713-569c-460c-d5be-13d125619482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.4950617585412994, IoU: 0.5993344316820423, Dice: 0.7044937282265303\n",
            "Validation Loss: 0.500605719089508, IoU: 0.5843105634450912, Dice: 0.6917952637672424\n",
            "Model saved at epoch 1\n",
            "Epoch 2/50, Loss: 0.4914667147719218, IoU: 0.6117084709529629, Dice: 0.7144371572130931\n",
            "Validation Loss: 0.49985160112380983, IoU: 0.5898717188835144, Dice: 0.6963595263957977\n",
            "Model saved at epoch 2\n",
            "Epoch 3/50, Loss: 0.4897690178629405, IoU: 0.6213400838320364, Dice: 0.7219486536974916\n",
            "Validation Loss: 0.49929597520828245, IoU: 0.5947220466136932, Dice: 0.7005916571617127\n",
            "Model saved at epoch 3\n",
            "Epoch 4/50, Loss: 0.48704598528777293, IoU: 0.6334767414781148, Dice: 0.7312306762039067\n",
            "Validation Loss: 0.4972623932361603, IoU: 0.6513597254753113, Dice: 0.7491750526428222\n",
            "Model saved at epoch 4\n",
            "Epoch 5/50, Loss: 0.48685904920933964, IoU: 0.6413610852704552, Dice: 0.7383057777723391\n",
            "Validation Loss: 0.4982065622806549, IoU: 0.5887878535985946, Dice: 0.6956394240856171\n",
            "Epoch 6/50, Loss: 0.4875860564901443, IoU: 0.6577212591906507, Dice: 0.7523012683836524\n",
            "Validation Loss: 0.4991003580093384, IoU: 0.6102045153379441, Dice: 0.7142870509624482\n",
            "Epoch 7/50, Loss: 0.4852431154477144, IoU: 0.6688541115341549, Dice: 0.7596185329312574\n",
            "Validation Loss: 0.49644115376472475, IoU: 0.6228171746730804, Dice: 0.7252751672267914\n",
            "Model saved at epoch 7\n",
            "Epoch 8/50, Loss: 0.48374879375070395, IoU: 0.6806603366892019, Dice: 0.7694529514172358\n",
            "Validation Loss: 0.4954272837638855, IoU: 0.6917156527042388, Dice: 0.7828710141181946\n",
            "Model saved at epoch 8\n",
            "Epoch 9/50, Loss: 0.4833837629792219, IoU: 0.6974428961139001, Dice: 0.7834751509918186\n",
            "Validation Loss: 0.49478346276283264, IoU: 0.7801819682121277, Dice: 0.8601735005378723\n",
            "Model saved at epoch 9\n",
            "Epoch 10/50, Loss: 0.4820803465124614, IoU: 0.7004978699895912, Dice: 0.7855723113892321\n",
            "Validation Loss: 0.4959565532207489, IoU: 0.6520470464229584, Dice: 0.7490927853584289\n",
            "Epoch 11/50, Loss: 0.48108569486531433, IoU: 0.7129797691594579, Dice: 0.7960493840916666\n",
            "Validation Loss: 0.49432280707359316, IoU: 0.7217357273101807, Dice: 0.8084298572540283\n",
            "Model saved at epoch 11\n",
            "Epoch 12/50, Loss: 0.48049653034486217, IoU: 0.7276754911669238, Dice: 0.8075715472955189\n",
            "Validation Loss: 0.4942269968986511, IoU: 0.7734477832317352, Dice: 0.8527826895713806\n",
            "Model saved at epoch 12\n",
            "Epoch 13/50, Loss: 0.48040701056311946, IoU: 0.7329306222364574, Dice: 0.812002817700485\n",
            "Validation Loss: 0.49573528242111203, IoU: 0.8730910468101502, Dice: 0.927641881942749\n",
            "Epoch 14/50, Loss: 0.4804938041759346, IoU: 0.7344953603075888, Dice: 0.814103416310337\n",
            "Validation Loss: 0.49699471950531005, IoU: 0.7468472166061402, Dice: 0.8333035535812378\n",
            "Epoch 15/50, Loss: 0.4790258172029507, IoU: 0.7494000111094968, Dice: 0.8254759668292637\n",
            "Validation Loss: 0.4946059715747833, IoU: 0.7898595890998841, Dice: 0.8666312370300293\n",
            "Epoch 16/50, Loss: 0.4785786433193736, IoU: 0.7654490674029806, Dice: 0.8372088107698692\n",
            "Validation Loss: 0.4943461887836456, IoU: 0.7565175473690033, Dice: 0.8380735154151917\n",
            "Epoch 17/50, Loss: 0.48007264132509214, IoU: 0.7552702624402836, Dice: 0.830974167365276\n",
            "Validation Loss: 0.493938152551651, IoU: 0.7568779187202453, Dice: 0.8386457045078277\n",
            "Model saved at epoch 17\n",
            "Epoch 18/50, Loss: 0.47782739946347275, IoU: 0.7954949561112418, Dice: 0.8613963062594274\n",
            "Validation Loss: 0.4945941796302795, IoU: 0.8593160691261291, Dice: 0.918311420917511\n",
            "Epoch 19/50, Loss: 0.47725255766552604, IoU: 0.7983472058159149, Dice: 0.8628448590547025\n",
            "Validation Loss: 0.4940610680580139, IoU: 0.7277367115020752, Dice: 0.8141266918182373\n",
            "Epoch 20/50, Loss: 0.47837791727212614, IoU: 0.7796393996941116, Dice: 0.8496774055524738\n",
            "Validation Loss: 0.4943033390045166, IoU: 0.7555971224308013, Dice: 0.8375127806663513\n",
            "Epoch 21/50, Loss: 0.4770341418579429, IoU: 0.7903427800494516, Dice: 0.8560772278827583\n",
            "Validation Loss: 0.49426725912094116, IoU: 0.8438319911956788, Dice: 0.907311987876892\n",
            "Epoch 22/50, Loss: 0.4764274951821554, IoU: 0.8040842098033357, Dice: 0.8670291339982293\n",
            "Validation Loss: 0.49371868109703065, IoU: 0.7665465242862701, Dice: 0.8468139896392822\n",
            "Model saved at epoch 22\n",
            "Epoch 23/50, Loss: 0.476277182618539, IoU: 0.821282594474014, Dice: 0.8810691648198221\n",
            "Validation Loss: 0.49475999355316164, IoU: 0.8067658565044403, Dice: 0.8788580131530762\n",
            "Epoch 24/50, Loss: 0.4763123997730647, IoU: 0.8202776170657304, Dice: 0.879498430801009\n",
            "Validation Loss: 0.4949384481906891, IoU: 0.8072889113426208, Dice: 0.8773492159843445\n",
            "Epoch 25/50, Loss: 0.4761742900707527, IoU: 0.8190859506825011, Dice: 0.8784412781516473\n",
            "Validation Loss: 0.4953522608280182, IoU: 0.8380009241104126, Dice: 0.9015210256576538\n",
            "Epoch 26/50, Loss: 0.47585861340254365, IoU: 0.8168113917082608, Dice: 0.8757883643437764\n",
            "Validation Loss: 0.49441673707962036, IoU: 0.8281407225131988, Dice: 0.8933962574005127\n",
            "Epoch 27/50, Loss: 0.47562960117401, IoU: 0.8299939151176673, Dice: 0.8863550873990068\n",
            "Validation Loss: 0.4934129238128662, IoU: 0.8545861968994141, Dice: 0.9141158156394958\n",
            "Model saved at epoch 27\n",
            "Epoch 28/50, Loss: 0.4751979045108883, IoU: 0.8296104987521847, Dice: 0.8862855488252259\n",
            "Validation Loss: 0.49415397095680236, IoU: 0.8724111933708191, Dice: 0.9256700286865235\n",
            "Epoch 29/50, Loss: 0.47586793849568165, IoU: 0.826511339632099, Dice: 0.884658733408846\n",
            "Validation Loss: 0.4964157671928406, IoU: 0.8671343870162964, Dice: 0.9219369282722473\n",
            "Epoch 30/50, Loss: 0.4753082316376254, IoU: 0.8417109860155635, Dice: 0.895995372426724\n",
            "Validation Loss: 0.49388291215896607, IoU: 0.8771196165084839, Dice: 0.9284539875984192\n",
            "Epoch 31/50, Loss: 0.47448897501546705, IoU: 0.863336459932451, Dice: 0.9109885948979688\n",
            "Validation Loss: 0.4941076381206512, IoU: 0.8389553232192993, Dice: 0.9020173192024231\n",
            "Epoch 32/50, Loss: 0.47477400638981015, IoU: 0.8506461749533694, Dice: 0.9026208419999676\n",
            "Validation Loss: 0.4934592022895813, IoU: 0.8736862320899963, Dice: 0.9266638417243958\n",
            "Epoch 33/50, Loss: 0.4746483409119223, IoU: 0.8457790146211902, Dice: 0.8980691231891305\n",
            "Validation Loss: 0.495215939283371, IoU: 0.8490297317504882, Dice: 0.9089912548065185\n",
            "Epoch 34/50, Loss: 0.4745509686048873, IoU: 0.8346331513332511, Dice: 0.8904535179723523\n",
            "Validation Loss: 0.4943578169345856, IoU: 0.845118070602417, Dice: 0.906578754901886\n",
            "Epoch 35/50, Loss: 0.47438525166102274, IoU: 0.8658619872526733, Dice: 0.9133881352202383\n",
            "Validation Loss: 0.4940928966999054, IoU: 0.8700485730171204, Dice: 0.9237020010948181\n",
            "Epoch 36/50, Loss: 0.47433242186933694, IoU: 0.8493509507940676, Dice: 0.9017478144335414\n",
            "Validation Loss: 0.4953822853565216, IoU: 0.8732463579177856, Dice: 0.9264260673522949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 가중치 로드\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/best_model.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agXNIUim6wmc",
        "outputId": "3ec63488-9ee9-4aca-f54e-a2b3fa581329"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = LesionDataset(test_df, '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/images/', transforms=transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "e2W4KDiE7CzF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "test_iou = 0\n",
        "test_dice = 0\n",
        "with torch.no_grad():\n",
        "    for images, masks in test_loader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.float().to(device)  # Convert masks to float\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        test_loss += loss.item()\n",
        "        outputs = torch.sigmoid(outputs)  # Apply sigmoid activation for thresholding\n",
        "        test_iou += iou_pytorch(outputs, masks)\n",
        "        test_dice += dice_coef(outputs, masks)\n",
        "test_iou /= len(test_loader)\n",
        "test_dice /= len(test_loader)\n",
        "print(f\"Test Loss: {test_loss/len(test_loader)}, IoU: {test_iou}, Dice: {test_dice}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtujC996zZG",
        "outputId": "3b53790a-15d5-4015-9631-fd37a2359a8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.49455246707749745, IoU: 0.851066068524406, Dice: 0.9112102843466259\n"
          ]
        }
      ]
    }
  ]
}