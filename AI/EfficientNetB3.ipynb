{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10306,"status":"ok","timestamp":1716992810368,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"iUsOlj9RWyKG"},"outputs":[],"source":["import pandas as pd\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torch\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import torch.nn as nn\n","import torchvision.models as models\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn.metrics import accuracy_score, f1_score\n","import matplotlib.pyplot as plt\n","import torch\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21000,"status":"ok","timestamp":1716992831364,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"V5e9ACHQW3SM","outputId":"77f1fdd1-8d5e-46f8-8e0b-d99174a68a49"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 드라이브를 마운트합니다.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716992831364,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"sPrYVtAOatiY"},"outputs":[],"source":["# 데이터셋 준비\n","data_dir = '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3364,"status":"ok","timestamp":1716992834726,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"n0zzgPB71rAH"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from torchvision import transforms, models\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, classification_report\n","import matplotlib.pyplot as plt\n","\n","# 데이터 로드\n","train_df = pd.read_csv('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/TrainData.csv')\n","valid_df = pd.read_csv('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/ValidData.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/TestData.csv')\n","\n","# 데이터 경로 설정\n","image_path = \"/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/dataset/images\"\n","\n","# Label Encoding\n","le = LabelEncoder()\n","train_df['Class'] = le.fit_transform(train_df['Class'])\n","valid_df['Class'] = le.transform(valid_df['Class'])\n","test_df['Class'] = le.transform(test_df['Class'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1716987014503,"user":{"displayName":"지수파띵","userId":"11322133048221709881"},"user_tz":-540},"id":"hSJMXjHg2IfE","outputId":"795c3b21-5fd2-4871-c4f5-a54bde5e05c1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'], dtype=object)"]},"metadata":{},"execution_count":5}],"source":["le.classes_"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716992834726,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"soc0ioet2Je3"},"outputs":[],"source":["class SkinDataset(Dataset):\n","    def __init__(self, dataframe, image_dir, transform=None):\n","        self.dataframe = dataframe\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx, 0]) + \".jpg\"\n","        image = Image.open(img_name)\n","        image = np.array(image)  # PIL 이미지를 numpy 배열로 변환\n","        label = self.dataframe.iloc[idx, 1]\n","        if self.transform:\n","            augmented = self.transform(image=image)  # 명명된 인수로 전달\n","            image = augmented[\"image\"]\n","        return image, label\n","\n","# 데이터 증강 정의\n","train_transform = A.Compose([\n","    A.CenterCrop(300, 300),             # 이미지의 중앙을 자릅니다\n","    A.Resize(128, 128),                 # 이미지를 128x128로 크기 조정합니다\n","    A.Rotate(limit=180, p=0.5),         # 이미지를 -180도에서 180도 사이로 랜덤하게 회전합니다\n","    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.5),  # 수평, 수직 이동 및 확대/축소\n","    A.HorizontalFlip(p=0.5),            # 이미지를 수평으로 뒤집습니다\n","    A.VerticalFlip(p=0.5),              # 이미지를 수직으로 뒤집습니다\n","    A.RandomBrightnessContrast(p=0.2),  # 랜덤하게 밝기 및 대비 조정\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2()\n","])\n","\n","transform = A.Compose([\n","    A.CenterCrop(300, 300),\n","    A.Resize(128, 128),\n","    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","    ToTensorV2()\n","])\n","\n","train_dataset = SkinDataset(train_df, image_path, transform=train_transform)\n","valid_dataset = SkinDataset(valid_df, image_path, transform=transform)\n","test_dataset = SkinDataset(test_df, image_path, transform=transform)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716992834726,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"yURzi7Z84c0p","outputId":"a83f7d6f-11d7-420f-b079-88768ac116ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1716992834726,"user":{"displayName":"여지수","userId":"09022417471355634477"},"user_tz":-540},"id":"46M-cAHmDQiw"},"outputs":[],"source":["batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","source":["model = models.efficientnet_b3(pretrained=True)\n","# EfficientNet 모델의 마지막 레이어 수정\n","num_ftrs = model.classifier[1].in_features\n","model.classifier[1] = nn.Linear(num_ftrs, 7)  # 7개의 클래스 출력\n","model = model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","num_epochs = 20\n","train_losses, valid_losses = [], []\n","train_accuracies, valid_accuracies = [], []"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYaRLKXyZoE4","executionInfo":{"status":"ok","timestamp":1716992847087,"user_tz":-540,"elapsed":1806,"user":{"displayName":"여지수","userId":"09022417471355634477"}},"outputId":"da24b2d1-f1d7-4d9e-e132-7cf849add472"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n","100%|██████████| 47.2M/47.2M [00:00<00:00, 148MB/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tT38lP0C2UJY","executionInfo":{"status":"ok","timestamp":1716979545068,"user_tz":-540,"elapsed":5705602,"user":{"displayName":"Gpt Chat","userId":"15931655597904794644"}},"outputId":"06d09ce9-5e52-46f0-9765-858506a01ade"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n","100%|██████████| 47.2M/47.2M [00:00<00:00, 124MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 0.8256, Train Acc: 0.7086, Val Loss: 0.8158, Val Acc: 0.7560\n","Epoch 2/20, Train Loss: 0.6922, Train Acc: 0.7496, Val Loss: 0.5692, Val Acc: 0.8000\n","Epoch 3/20, Train Loss: 0.6456, Train Acc: 0.7749, Val Loss: 0.5825, Val Acc: 0.7900\n","Epoch 4/20, Train Loss: 0.6008, Train Acc: 0.7854, Val Loss: 0.4883, Val Acc: 0.8250\n","Epoch 5/20, Train Loss: 0.5715, Train Acc: 0.7936, Val Loss: 0.4984, Val Acc: 0.8360\n","Epoch 6/20, Train Loss: 0.5440, Train Acc: 0.8056, Val Loss: 0.5106, Val Acc: 0.8190\n","Epoch 7/20, Train Loss: 0.5187, Train Acc: 0.8177, Val Loss: 0.6019, Val Acc: 0.7890\n","Epoch 8/20, Train Loss: 0.5102, Train Acc: 0.8145, Val Loss: 0.5290, Val Acc: 0.8260\n","Epoch 9/20, Train Loss: 0.4949, Train Acc: 0.8221, Val Loss: 0.4432, Val Acc: 0.8370\n","Epoch 10/20, Train Loss: 0.4830, Train Acc: 0.8276, Val Loss: 0.4473, Val Acc: 0.8460\n","Epoch 11/20, Train Loss: 0.4585, Train Acc: 0.8340, Val Loss: 0.4802, Val Acc: 0.8410\n","Epoch 12/20, Train Loss: 0.4345, Train Acc: 0.8409, Val Loss: 0.4770, Val Acc: 0.8390\n","Epoch 13/20, Train Loss: 0.4236, Train Acc: 0.8502, Val Loss: 0.4444, Val Acc: 0.8420\n","Epoch 14/20, Train Loss: 0.4134, Train Acc: 0.8527, Val Loss: 0.5172, Val Acc: 0.8280\n","Epoch 15/20, Train Loss: 0.4256, Train Acc: 0.8496, Val Loss: 0.4099, Val Acc: 0.8470\n","Epoch 16/20, Train Loss: 0.3936, Train Acc: 0.8581, Val Loss: 0.4459, Val Acc: 0.8430\n","Epoch 17/20, Train Loss: 0.3873, Train Acc: 0.8561, Val Loss: 0.4746, Val Acc: 0.8500\n","Epoch 18/20, Train Loss: 0.3672, Train Acc: 0.8658, Val Loss: 0.4516, Val Acc: 0.8420\n","Epoch 19/20, Train Loss: 0.3538, Train Acc: 0.8699, Val Loss: 0.4538, Val Acc: 0.8440\n","Epoch 20/20, Train Loss: 0.3568, Train Acc: 0.8713, Val Loss: 0.4238, Val Acc: 0.8510\n"]}],"source":["for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct = 0.0, 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = correct.double() / len(train_loader.dataset)\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_acc.item())\n","\n","    model.eval()\n","    running_loss, correct = 0.0, 0\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","    epoch_acc = correct.double() / len(valid_loader.dataset)\n","    valid_losses.append(epoch_loss)\n","    valid_accuracies.append(epoch_acc.item())\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, Val Loss: {valid_losses[-1]:.4f}, Val Acc: {valid_accuracies[-1]:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqOAhIe_DL9y"},"outputs":[],"source":["# 모델 저장\n","torch.save(model.state_dict(), '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_cls_V1.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEtCAFRnclmX"},"outputs":[],"source":["# loss, accuracy 저장\n","# 학습 및 검증 loss와 accuracy 저장\n","with open('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_metrics_V1.pkl', 'wb') as f:\n","    pickle.dump({\n","        'train_losses': train_losses,\n","        'valid_losses': valid_losses,\n","        'train_accuracies': train_accuracies,\n","        'valid_accuracies': valid_accuracies\n","    }, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cASFVMhcWFY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716983245939,"user_tz":-540,"elapsed":2863053,"user":{"displayName":"Gpt Chat","userId":"15931655597904794644"}},"outputId":"ce953c35-06a4-4a7c-dd80-87cd7ee60a85"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 0.3390, Train Acc: 0.8764, Val Loss: 0.4175, Val Acc: 0.8690\n","Epoch 2/20, Train Loss: 0.3337, Train Acc: 0.8792, Val Loss: 0.4191, Val Acc: 0.8680\n","Epoch 3/20, Train Loss: 0.3172, Train Acc: 0.8841, Val Loss: 0.4566, Val Acc: 0.8540\n","Epoch 4/20, Train Loss: 0.3064, Train Acc: 0.8854, Val Loss: 0.4494, Val Acc: 0.8560\n","Epoch 5/20, Train Loss: 0.2919, Train Acc: 0.8960, Val Loss: 0.4514, Val Acc: 0.8590\n","Epoch 6/20, Train Loss: 0.2840, Train Acc: 0.8939, Val Loss: 0.4328, Val Acc: 0.8650\n","Epoch 7/20, Train Loss: 0.2712, Train Acc: 0.9029, Val Loss: 0.4502, Val Acc: 0.8590\n","Epoch 8/20, Train Loss: 0.2827, Train Acc: 0.8979, Val Loss: 0.4554, Val Acc: 0.8610\n","Epoch 9/20, Train Loss: 0.2613, Train Acc: 0.9049, Val Loss: 0.4937, Val Acc: 0.8490\n","Epoch 10/20, Train Loss: 0.2584, Train Acc: 0.9057, Val Loss: 0.4186, Val Acc: 0.8660\n","Epoch 11/20, Train Loss: 0.2496, Train Acc: 0.9099, Val Loss: 0.5361, Val Acc: 0.8410\n","Epoch 12/20, Train Loss: 0.2418, Train Acc: 0.9115, Val Loss: 0.4383, Val Acc: 0.8690\n","Epoch 13/20, Train Loss: 0.2292, Train Acc: 0.9131, Val Loss: 0.4385, Val Acc: 0.8690\n","Epoch 14/20, Train Loss: 0.2402, Train Acc: 0.9139, Val Loss: 0.3998, Val Acc: 0.8670\n","Epoch 15/20, Train Loss: 0.2287, Train Acc: 0.9166, Val Loss: 0.4736, Val Acc: 0.8710\n","Epoch 16/20, Train Loss: 0.2141, Train Acc: 0.9225, Val Loss: 0.4402, Val Acc: 0.8760\n","Epoch 17/20, Train Loss: 0.2198, Train Acc: 0.9211, Val Loss: 0.4459, Val Acc: 0.8720\n","Epoch 18/20, Train Loss: 0.2131, Train Acc: 0.9238, Val Loss: 0.4480, Val Acc: 0.8590\n","Epoch 19/20, Train Loss: 0.1984, Train Acc: 0.9265, Val Loss: 0.4941, Val Acc: 0.8690\n","Epoch 20/20, Train Loss: 0.1876, Train Acc: 0.9326, Val Loss: 0.4801, Val Acc: 0.8730\n"]}],"source":["# 추가 학습 진행\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct = 0.0, 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = correct.double() / len(train_loader.dataset)\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_acc.item())\n","\n","    model.eval()\n","    running_loss, correct = 0.0, 0\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","    epoch_acc = correct.double() / len(valid_loader.dataset)\n","    valid_losses.append(epoch_loss)\n","    valid_accuracies.append(epoch_acc.item())\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, Val Loss: {valid_losses[-1]:.4f}, Val Acc: {valid_accuracies[-1]:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_K93icIZcfRL"},"outputs":[],"source":["# 모델 저장\n","torch.save(model.state_dict(), '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_cls_V1.pth')"]},{"cell_type":"code","source":["# 추가 학습 진행\n","num_epochs = 160\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct = 0.0, 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = correct.double() / len(train_loader.dataset)\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_acc.item())\n","\n","    model.eval()\n","    running_loss, correct = 0.0, 0\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","    epoch_acc = correct.double() / len(valid_loader.dataset)\n","    valid_losses.append(epoch_loss)\n","    valid_accuracies.append(epoch_acc.item())\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, Val Loss: {valid_losses[-1]:.4f}, Val Acc: {valid_accuracies[-1]:.4f}')\n","    # 모델 저장\n","    torch.save(model.state_dict(), '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_cls_V1.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GbK1h3HDCaG","outputId":"aa724ea6-c0c6-4873-e0a4-fd031aacacbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/160, Train Loss: 0.1905, Train Acc: 0.9298, Val Loss: 0.4779, Val Acc: 0.8460\n","Epoch 2/160, Train Loss: 0.1755, Train Acc: 0.9362, Val Loss: 0.4964, Val Acc: 0.8580\n","Epoch 3/160, Train Loss: 0.1967, Train Acc: 0.9308, Val Loss: 0.4770, Val Acc: 0.8570\n","Epoch 4/160, Train Loss: 0.1837, Train Acc: 0.9355, Val Loss: 0.4344, Val Acc: 0.8670\n","Epoch 5/160, Train Loss: 0.1768, Train Acc: 0.9361, Val Loss: 0.4884, Val Acc: 0.8690\n","Epoch 6/160, Train Loss: 0.1729, Train Acc: 0.9378, Val Loss: 0.5030, Val Acc: 0.8760\n","Epoch 7/160, Train Loss: 0.1643, Train Acc: 0.9414, Val Loss: 0.4995, Val Acc: 0.8650\n","Epoch 8/160, Train Loss: 0.1669, Train Acc: 0.9418, Val Loss: 0.4877, Val Acc: 0.8650\n","Epoch 9/160, Train Loss: 0.1600, Train Acc: 0.9422, Val Loss: 0.5126, Val Acc: 0.8480\n","Epoch 10/160, Train Loss: 0.1609, Train Acc: 0.9419, Val Loss: 0.4648, Val Acc: 0.8870\n","Epoch 11/160, Train Loss: 0.1537, Train Acc: 0.9464, Val Loss: 0.4413, Val Acc: 0.8690\n","Epoch 12/160, Train Loss: 0.1520, Train Acc: 0.9476, Val Loss: 0.5409, Val Acc: 0.8620\n","Epoch 13/160, Train Loss: 0.1572, Train Acc: 0.9461, Val Loss: 0.4634, Val Acc: 0.8770\n","Epoch 14/160, Train Loss: 0.1452, Train Acc: 0.9488, Val Loss: 0.5192, Val Acc: 0.8680\n","Epoch 15/160, Train Loss: 0.1381, Train Acc: 0.9502, Val Loss: 0.4695, Val Acc: 0.8800\n","Epoch 16/160, Train Loss: 0.1515, Train Acc: 0.9477, Val Loss: 0.4288, Val Acc: 0.8820\n","Epoch 17/160, Train Loss: 0.1261, Train Acc: 0.9551, Val Loss: 0.5242, Val Acc: 0.8650\n","Epoch 18/160, Train Loss: 0.1473, Train Acc: 0.9484, Val Loss: 0.4002, Val Acc: 0.8890\n","Epoch 19/160, Train Loss: 0.1225, Train Acc: 0.9564, Val Loss: 0.4740, Val Acc: 0.8710\n","Epoch 20/160, Train Loss: 0.1438, Train Acc: 0.9488, Val Loss: 0.4968, Val Acc: 0.8730\n","Epoch 21/160, Train Loss: 0.1285, Train Acc: 0.9517, Val Loss: 0.4618, Val Acc: 0.8710\n","Epoch 22/160, Train Loss: 0.1275, Train Acc: 0.9577, Val Loss: 0.5047, Val Acc: 0.8650\n","Epoch 23/160, Train Loss: 0.1110, Train Acc: 0.9604, Val Loss: 0.5131, Val Acc: 0.8760\n"]}]},{"cell_type":"code","source":["# 2. 저장된 모델 가중치 로드\n","model.load_state_dict(torch.load('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_cls_V1.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szRZ0SXNZscm","executionInfo":{"status":"ok","timestamp":1716992860224,"user_tz":-540,"elapsed":2275,"user":{"displayName":"여지수","userId":"09022417471355634477"}},"outputId":"5af77c23-a674-4531-e970-b64652d79d65"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 추가 학습 진행\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss, correct = 0.0, 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_acc = correct.double() / len(train_loader.dataset)\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_acc.item())\n","\n","    model.eval()\n","    running_loss, correct = 0.0, 0\n","    with torch.no_grad():\n","        for inputs, labels in valid_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","    epoch_acc = correct.double() / len(valid_loader.dataset)\n","    valid_losses.append(epoch_loss)\n","    valid_accuracies.append(epoch_acc.item())\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, Val Loss: {valid_losses[-1]:.4f}, Val Acc: {valid_accuracies[-1]:.4f}')\n","    # 모델 저장\n","    torch.save(model.state_dict(), '/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_cls_V1.pth')"],"metadata":{"id":"pifkFr5pZcTg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5979,"status":"ok","timestamp":1716817973917,"user":{"displayName":"지수파띵","userId":"11322133048221709881"},"user_tz":-540},"id":"x4pGha9d3sok","outputId":"386c927b-a1b6-4db4-b538-46c160c3f79e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pickle-mixin\n","  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pickle-mixin\n","  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=5991 sha256=1104a0e67a3fcee4da99ff6913f2548a1711ca130a7dad4125cc51af320caae5\n","  Stored in directory: /root/.cache/pip/wheels/3e/c6/e9/d1b0a34e1efc6c3ec9c086623972c6de6317faddb2af0a619c\n","Successfully built pickle-mixin\n","Installing collected packages: pickle-mixin\n","Successfully installed pickle-mixin-1.0.2\n"]}],"source":["!pip install pickle-mixin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ziMQ5MMiU3X6"},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQuvJTC13gW6"},"outputs":[],"source":["# loss, accuracy 저장\n","# 학습 및 검증 loss와 accuracy 저장\n","with open('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_metrics_V1.pkl', 'wb') as f:\n","    pickle.dump({\n","        'train_losses': train_losses,\n","        'valid_losses': valid_losses,\n","        'train_accuracies': train_accuracies,\n","        'valid_accuracies': valid_accuracies\n","    }, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJBDLvhV3qfF"},"outputs":[],"source":["# 학습 및 검증 결과 불러오기\n","with open('/content/drive/MyDrive/클라우드컴퓨팅 텀프로젝트/model/EfficientNetB3_metrics_V1.pkl', 'rb') as f:\n","    metrics = pickle.load(f)\n","    train_losses = metrics['train_losses']\n","    valid_losses = metrics['valid_losses']\n","    train_accuracies = metrics['train_accuracies']\n","    valid_accuracies = metrics['valid_accuracies']"]},{"cell_type":"code","source":["# 성능 평가\n","model.eval()\n","all_preds, all_labels = [], []\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# Confusion Matrix\n","cm = confusion_matrix(all_labels, all_preds)\n","print('Confusion Matrix:')\n","print(cm)\n","\n","# Class별 Accuracy\n","report = classification_report(all_labels, all_preds, target_names=le.classes_)\n","print('Classification Report:')\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcwGcCXfwFtd","executionInfo":{"status":"ok","timestamp":1716993166027,"user_tz":-540,"elapsed":260861,"user":{"displayName":"여지수","userId":"09022417471355634477"}},"outputId":"c03feae3-5b3f-42ba-cf65-b9f9b6aeeecc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n","[[ 23   3   5   0   0   2   0]\n"," [  1  46   2   0   0   3   0]\n"," [  9   2  73   0   3  23   0]\n"," [  0   1   1   8   1   1   0]\n"," [  2   2   6   1  59  42   0]\n"," [  0   2   3   2   4 659   1]\n"," [  0   0   1   0   0   0  14]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","       AKIEC       0.66      0.70      0.68        33\n","         BCC       0.82      0.88      0.85        52\n","         BKL       0.80      0.66      0.73       110\n","          DF       0.73      0.67      0.70        12\n","         MEL       0.88      0.53      0.66       112\n","          NV       0.90      0.98      0.94       671\n","        VASC       0.93      0.93      0.93        15\n","\n","    accuracy                           0.88      1005\n","   macro avg       0.82      0.76      0.78      1005\n","weighted avg       0.88      0.88      0.87      1005\n","\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}